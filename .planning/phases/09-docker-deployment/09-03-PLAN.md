---
phase: 09-docker-deployment
plan: 03
type: execute
wave: 2
depends_on: ["09-01", "09-02"]
files_modified:
  - docker-compose.yml
  - .env.example
autonomous: false

must_haves:
  truths:
    - "docker compose up starts all services"
    - "Backend waits for database to be healthy before starting"
    - "Frontend waits for backend to be healthy before starting"
    - "PostgreSQL data persists across restarts"
    - "Services can communicate via Docker network"
  artifacts:
    - path: "docker-compose.yml"
      provides: "Service orchestration configuration"
      contains: "services:"
    - path: ".env.example"
      provides: "Environment variable template"
      contains: "POSTGRES_PASSWORD"
  key_links:
    - from: "docker-compose.yml backend"
      to: "db service"
      via: "depends_on with service_healthy"
      pattern: "condition: service_healthy"
    - from: "docker-compose.yml frontend"
      to: "backend service"
      via: "depends_on with service_healthy"
      pattern: "condition: service_healthy"
---

<objective>
Create Docker Compose orchestration to run the complete StockUs stack (PostgreSQL, backend, frontend).

Purpose: Enable one-command deployment of the entire application with proper service dependencies, health checks, and environment management.
Output: docker-compose.yml and .env.example for production deployment
</objective>

<execution_context>
@/Users/dio/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dio/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/09-docker-deployment/09-RESEARCH.md
@.planning/phases/09-docker-deployment/09-01-SUMMARY.md
@.planning/phases/09-docker-deployment/09-02-SUMMARY.md

@backend/src/config/env.ts
@backend/.env.example
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create docker-compose.yml</name>
  <files>docker-compose.yml</files>
  <action>
Create docker-compose.yml at the project root to orchestrate all services.

**Services:**

1. **db (PostgreSQL)**
   - image: postgres:16-alpine
   - environment: POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB from env vars with defaults
   - volumes: pgdata:/var/lib/postgresql/data (named volume for persistence)
   - healthcheck: pg_isready command
   - restart: unless-stopped
   - resource limits: 1 CPU, 512M memory

2. **backend (Hono API)**
   - build: context ./backend
   - environment:
     - DATABASE_URL constructed from POSTGRES vars, host is 'db'
     - NODE_ENV=production
     - PORT=3000 (standardize to 3000 inside container)
     - All auth, email, Midtrans, R2 vars from env
   - depends_on: db with condition: service_healthy
   - healthcheck: node http to /health/ready (readiness probe checks DB)
   - restart: unless-stopped
   - resource limits: 1.5 CPU, 512M memory
   - No port expose (internal only, frontend proxies or direct access optional)

3. **frontend (Next.js)**
   - build: context ./frontend
   - environment:
     - NEXT_PUBLIC_API_URL (for client-side API calls)
     - NODE_ENV=production
   - depends_on: backend with condition: service_healthy
   - ports: "3000:3000" (expose frontend to host)
   - healthcheck: node http to /api/health
   - restart: unless-stopped
   - resource limits: 1 CPU, 512M memory

**Network:** Default bridge network is sufficient; services reference each other by name.

**Volume:** Named volume pgdata for PostgreSQL persistence.

**Environment variables format:**
- Use ${VAR:-default} syntax for optional defaults
- POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB for database
- Backend constructs DATABASE_URL from these parts

**Health check details:**
- db: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
- backend: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health/ready', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
- frontend: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/api/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]

NOTE: Backend uses /health/ready which verifies database connectivity.
  </action>
  <verify>
Run: docker compose config (validates compose file syntax)
  </verify>
  <done>docker-compose.yml validates with all three services, health checks, and depends_on conditions</done>
</task>

<task type="auto">
  <name>Task 2: Create root .env.example</name>
  <files>.env.example</files>
  <action>
Create .env.example at project root with all required environment variables for Docker Compose.

**Database section:**
```
# Database (PostgreSQL)
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=stockus
```

**Backend section (mirrors backend/.env.example but adapted for Docker):**
```
# Backend Server
NODE_ENV=production
PORT=3000

# JWT Authentication
JWT_SECRET=your-secret-key-at-least-32-characters-long
JWT_ACCESS_EXPIRES_MINUTES=15
JWT_REFRESH_EXPIRES_DAYS=7

# Email (Resend)
RESEND_API_KEY=re_your_api_key
EMAIL_FROM=noreply@yourdomain.com

# URLs (adjust for production domain)
FRONTEND_URL=http://localhost:3000
BACKEND_URL=http://backend:3000

# Midtrans Payment Gateway
MIDTRANS_SERVER_KEY=your_server_key
MIDTRANS_CLIENT_KEY=your_client_key
MIDTRANS_IS_PRODUCTION=false

# Referral System
REFERRAL_REWARD_AMOUNT=50000

# Cloudflare R2 Storage
CLOUDFLARE_ACCOUNT_ID=your_account_id
R2_ACCESS_KEY_ID=your_access_key
R2_SECRET_ACCESS_KEY=your_secret_key
R2_BUCKET_NAME=your_bucket_name
VIDEO_UPLOAD_URL_EXPIRY=900
VIDEO_PLAYBACK_URL_EXPIRY=3600
```

**Frontend section:**
```
# Frontend
NEXT_PUBLIC_API_URL=http://localhost:3001
```

Add comments explaining:
- DATABASE_URL is constructed automatically in docker-compose.yml
- BACKEND_URL uses 'backend' hostname for internal Docker networking
- NEXT_PUBLIC_API_URL should point to backend external URL for client-side requests
- For production: update URLs to actual domain names
  </action>
  <verify>
File exists at .env.example with POSTGRES_PASSWORD placeholder
  </verify>
  <done>.env.example contains all required environment variables with helpful comments</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete Docker Compose stack with PostgreSQL, backend, and frontend services</what-built>
  <how-to-verify>
1. Copy .env.example to .env and fill in real values (or use test values for local verification)
2. Run: docker compose build
3. Run: docker compose up -d
4. Wait for services to become healthy: docker compose ps (should show all services as "healthy")
5. Test frontend: curl http://localhost:3000 (should return HTML)
6. Test backend health via frontend network: docker compose exec frontend node -e "require('http').get('http://backend:3000/health', console.log)"
7. Check logs: docker compose logs --tail=20
8. Cleanup: docker compose down

Expected:
- All three services start and become healthy
- Frontend accessible on port 3000
- Backend connected to PostgreSQL
- No errors in logs

NOTE: Full application functionality requires actual credentials (Midtrans, R2, Resend). This verification confirms Docker infrastructure works correctly.
  </how-to-verify>
  <resume-signal>Type "approved" if Docker stack runs successfully, or describe issues</resume-signal>
</task>

</tasks>

<verification>
1. docker-compose.yml exists at project root
2. .env.example exists at project root
3. docker compose config runs without errors
4. Services have depends_on with service_healthy condition
5. PostgreSQL uses named volume (pgdata)
6. All services have health checks and restart policies
</verification>

<success_criteria>
- docker compose build completes successfully
- docker compose up starts all services
- Services start in correct order (db -> backend -> frontend)
- Health checks pass for all services
- Frontend accessible at http://localhost:3000
- PostgreSQL data persists in pgdata volume
- .env.example documents all required variables
</success_criteria>

<output>
After completion, create `.planning/phases/09-docker-deployment/09-03-SUMMARY.md`
</output>
